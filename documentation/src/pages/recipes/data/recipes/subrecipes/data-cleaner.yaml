version: 1.0.0
title: Data Cleaner
description: Performs intelligent data cleaning including missing value handling, duplicate removal, and outlier treatment

instructions: |
  You are a data cleaning specialist. Clean and prepare datasets for analysis while 
  preserving data integrity and documenting all transformations applied.
  
  Use smart, context-aware cleaning strategies appropriate for the data type and domain.

parameters:
  - key: data_file
    input_type: string
    requirement: required
    description: Path to the data file to clean
  
  - key: handle_missing
    input_type: string
    requirement: optional
    default: "smart"
    description: Strategy for missing values - options are 'remove', 'mean', 'median', 'mode', 'smart'
  
  - key: remove_duplicates
    input_type: string
    requirement: optional
    default: "true"
    description: Whether to remove duplicate rows (true/false)
  
  - key: outlier_strategy
    input_type: string
    requirement: optional
    default: "flag"
    description: How to handle outliers - options are 'keep', 'remove', 'flag', 'cap'

extensions:
  - type: builtin
    name: developer
    timeout: 600
    bundled: true
    description: For data manipulation and cleaning operations

prompt: |
  Clean {{ data_file }} efficiently using pandas.
  
  Important: Handle file paths correctly for all operating systems.
  Use os.path.join() or pathlib for cross-platform compatibility.
  Detect OS and use appropriate separators.
  
  Strategy: {{ handle_missing }} for missing, {{ remove_duplicates }} duplicates, {{ outlier_strategy }} outliers
  
  Quick cleaning steps:
  1. Load data with pd.read_csv/json
  2. Drop duplicates if {{ remove_duplicates }}=="true"
  3. Handle missing:
     - {{ handle_missing }}=="smart": fillna(median) for numeric, fillna(mode) for objects
     - {{ handle_missing }}=="remove": dropna()
  4. Outliers: {% if outlier_strategy == "remove" %}IQR method{% else %}keep all{% endif %}
  5. Save as {filename}_cleaned.csv in same directory as input
  
  Error handling:
  - Catch and report file I/O errors
  - Handle empty dataframes gracefully
  - Validate operations succeeded before proceeding
  
  Return brief report: rows before/after, columns cleaned, transformations applied.